{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import other useful Python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikesorting_fullpursuit as fbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikesorting_fullpursuit.test import gen_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by setting up a gen_dataset object to make and sort synthetic data\n",
    "n_chans = 4 # Number of channels to make in test dataset\n",
    "v_duration = 30 # Test dataset duration in seconds\n",
    "random_seed = None # Set seed of numpy random number generator for spike times\n",
    "neuron_templates = None # Just use default pre-loaded template waveforms to generate spike voltage traces\n",
    "frequency_range = (300, 6000) # Frequencies of dataset in Hz\n",
    "samples_per_second = 40000 # Sampling rate of 40kHz\n",
    "amplitude = 1 # Amplitude of 3 standard deviations of noise\n",
    "percent_shared_noise = .3 # Create share d noise across channels\n",
    "correlate1_2 = (.10, 10) # Set 15% of neuron 2 spikes to occur within 10 samples of a neuron 1 spike\n",
    "electrode_type = 'tetrode' # Choose pre-loaded electrode type of tetrode and all channels in neighborhood\n",
    "voltage_dtype = np.float32 # Create voltage array as float 32\n",
    "\n",
    "# Create the test dataset object\n",
    "test_data = gen_dataset.TestDataset(n_chans, v_duration, random_seed, neuron_templates, frequency_range, \n",
    "                                    samples_per_second, amplitude, percent_shared_noise,\n",
    "                                    correlate1_2, electrode_type, voltage_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the noise voltage array, without spikes, assigned to test_date.voltage_array\n",
    "test_data.gen_noise_voltage_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the neurons' properties in the dataset\n",
    "firing_rates = np.array([90, 100]) # Firing rates\n",
    "template_inds = np.array([1, 0]) # Templates used for waveforms\n",
    "chan_scaling_factors = 2*np.array([[1.85, 2.25, 1.65, .5], [3.85, 3.95, 1.95, 3.7]]) # Amplitude of neurons on each of the 4 channels\n",
    "refractory_win = 1.5e-3 # Set refractory period at 1.5 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the test dataset by choosing spike times and adding them according to the specified properties\n",
    "test_data.gen_test_dataset(firing_rates, template_inds, chan_scaling_factors, refractory_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two templates used to generate spikes. Templates are concatenated horizontally across channels for plotting.\n",
    "w_color = ['b', 'r']\n",
    "\n",
    "# Plot each neuron template\n",
    "n_neurons = len(test_data.actual_templates)\n",
    "for n in range(0, n_neurons): \n",
    "    use_color = w_color.pop(0)\n",
    "    \n",
    "    # Plot template for each channel\n",
    "    n_template_channels = test_data.actual_templates[n].shape[0]\n",
    "    n_template_samples = test_data.actual_templates[n].shape[1]\n",
    "    for chan in range(0, n_template_channels): \n",
    "        chan_x_inds = np.arange(n_template_samples*chan, n_template_samples*(chan+1))\n",
    "        _ = plt.plot(chan_x_inds, test_data.actual_templates[n][chan, :], color=use_color)\n",
    "        \n",
    "        # Add vertical lines to delineate channel boundaries for templates\n",
    "        if chan > 0:\n",
    "            plt.axvline(n_template_samples*chan, color='k')\n",
    "ag = plt.gcf()\n",
    "ag.set_size_inches(20, 5)\n",
    "_ = plt.xlim([0, n_template_channels*n_template_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the synthetic voltage for each channel within the window \"v_boundaries\" to see that we have successfully added spikes\n",
    "v_boundaries = [40000 - 5000, 40000 + 5000]\n",
    "for chan in range(0, test_data.num_channels):\n",
    "    plt.plot(np.arange(v_boundaries[0], v_boundaries[1]), \n",
    "             test_data.Probe.voltage[chan, v_boundaries[0]:v_boundaries[1]] - chan*5, color=[.7, .7, .7])\n",
    "ag = plt.gcf()\n",
    "ag.set_size_inches(20, 5)\n",
    "_ = plt.xlim(v_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sorting algorithm on the synthetically generated dataset.\n",
    "\n",
    "# Some of the possible input variables extracted to play with\n",
    "sigma = 4.0 # Sigma for detecting events/spike clips\n",
    "clip_width = [-10e-4, 10e-4] # Spike clip width used for finding templates (in ms)\n",
    "check_components = 20 # Number of PCs to check when searching for best PCs to use\n",
    "max_components = 5 # Maximum number of PCs to use for clustering\n",
    "p_value_cut_thresh = .01 # P-value used to determine whether to split clusters in iso-cut algorithm\n",
    "sigma_bp_noise = 2.326 # Threshold for adding spikes in binary pursuit relative to expected noise variance\n",
    "log_dir = None # You can optionally enter a directory string where more detailed text about the sorting progress and errors will be printed.\n",
    "\n",
    "# Resets random seed to the one last used so that results are repeatable\n",
    "np.random.set_state(test_data.random_state)\n",
    "\n",
    "# Enter the remaining variables for clarity. Run sorter and get outputs.\n",
    "sort_data, work_items, sort_info = test_data.sort_test_dataset_parallel({'p_value_cut_thresh': p_value_cut_thresh, 'sigma': sigma,\n",
    "                                       'clip_width': clip_width, 'check_components': check_components, \n",
    "                                       'max_components': max_components, 'verbose': True, 'do_ZCA_transform': True,\n",
    "                                       'min_firing_rate': 0.1, 'add_peak_valley': False,\n",
    "                                       'do_branch_PCA': True, 'max_gpu_memory': .1 * (1024 * 1024 * 1024),\n",
    "                                       'use_rand_init': True, 'segment_duration': 600, 'segment_overlap': 30, \n",
    "                                       'test_flag': False, 'log_dir': log_dir, 'do_branch_PCA_by_chan': True, 'sort_peak_clips_only': True,\n",
    "                                        'get_adjusted_clips': False,\n",
    "                                        'n_cov_samples': 20000,\n",
    "                                        'sigma_bp_noise': 2.326, 'sigma_bp_CI': 12.0, \n",
    "                                        'max_binary_pursuit_clip_width_factor': 1.,\n",
    "                                        'do_overlap_recheck': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step in automated post-processing\n",
    "# Set a few variables that can allow easy detection of units that are poor\n",
    "absolute_refractory_period = 10e-4 # Refractory period (in ms) will be used to determine potential violations in sorting accuracy\n",
    "# Max allowable ratio between refractory period violations and maximal bin of ACG. Units that violate will be deleted. Setting to 1. allows all units\n",
    "max_mua_ratio = 1. \n",
    "min_snr = 0 # Minimal SNR a unit must have to be included in post-processing\n",
    "min_overlapping_spikes = .75 # Percentage of spikes required with nearly identical spike times in adjacent segments for them to combine in stitching\n",
    "\n",
    "# Create the work_summary postprocessing object\n",
    "work_summary = fbp.postprocessing.WorkItemSummary(sort_data, work_items, sort_info, \n",
    "                                           absolute_refractory_period=absolute_refractory_period, max_mua_ratio=max_mua_ratio,\n",
    "                                           min_snr=min_snr, min_overlapping_spikes=min_overlapping_spikes, \n",
    "                                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No segments in the example (segment_duration > duration of synthetic data) but done as example\n",
    "work_summary.stitch_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the sorted output data into dictionaries by time segment. \n",
    "work_summary.summarize_neurons_by_seg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally summarize neurons across channels (combining and removing duplicate neurons across space) to get a list of sorted \"neurons\"\n",
    "neurons = work_summary.summarize_neurons_across_channels(overlap_ratio_threshold=np.inf, min_segs_per_unit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some basic information about our sorted units like number of spikes, firing rate, SNR, proportion MUA ISI violations\n",
    "fmtL = \"Unit: {:.0f} on chans {}; n spikes = {:.0f}; FR = {:.0f}; Dur = {:.0f}; SNR = {:.2f}; MUA = {:.2f}; TolInds = {:.0f}\"\n",
    "for ind, n in enumerate(neurons):\n",
    "    print_vals = [ind, n['channel'], n['spike_indices'].size, n['firing_rate'], n['duration_s'], n['snr']['average'], n['fraction_mua'], n['duplicate_tol_inds']]\n",
    "    print(fmtL.format(*print_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match the ground truth units to the sorted neurons with the most true positives\n",
    "test_match_to_neurons = {}\n",
    "for test_num in range(0, len(test_data.actual_IDs)):\n",
    "    max_true_positives = -np.inf\n",
    "    for unit_num in range(0, len(neurons)):\n",
    "        overlapping_spike_bool = fbp.analyze_spike_timing.find_overlapping_spike_bool(test_data.actual_IDs[test_num], \n",
    "                                                                                      neurons[unit_num]['spike_indices'], overlap_tol=10)\n",
    "        true_positives = np.count_nonzero(overlapping_spike_bool)\n",
    "        if true_positives > max_true_positives:\n",
    "            max_true_positives = true_positives\n",
    "            test_match_to_neurons[test_num] = unit_num\n",
    "\n",
    "for test_num in range(0, len(test_data.actual_IDs)):\n",
    "    print(\"Matched actual unit\", test_num, \"to sorted neuron\", test_match_to_neurons[test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the templates of the sorted neurons\n",
    "for n in test_match_to_neurons:\n",
    "    n_num = test_match_to_neurons[n]\n",
    "    for chan in neurons[n_num]['channel']:\n",
    "        plt.plot(neurons[n_num]['template'][chan][0:])\n",
    "ag = plt.gcf()\n",
    "ag.set_size_inches(10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print true positive and false discoveries for best matching to ground truth neuron 1\n",
    "ground_truth_unit = 0\n",
    "tol_inds = 10 # Match within a tolerance of 10 time samples\n",
    "overlapping_spike_bool = fbp.analyze_spike_timing.find_overlapping_spike_bool(test_data.actual_IDs[ground_truth_unit], neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'], overlap_tol=tol_inds)\n",
    "true_positives = np.count_nonzero(overlapping_spike_bool)\n",
    "\n",
    "print(\"False discoveries are\", 100 * (neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'].size - true_positives) / neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'].size)\n",
    "print(\"True positives are\", 100 * true_positives / test_data.actual_IDs[ground_truth_unit].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print true positive and false discoveries for best matching to ground truth neuron 1\n",
    "ground_truth_unit = 1\n",
    "tol_inds = 10 # Match within a tolerance of 10 time samples\n",
    "overlapping_spike_bool = fbp.analyze_spike_timing.find_overlapping_spike_bool(test_data.actual_IDs[ground_truth_unit], neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'], overlap_tol=tol_inds)\n",
    "true_positives = np.count_nonzero(overlapping_spike_bool)\n",
    "\n",
    "print(\"False discoveries are\", 100 * (neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'].size - true_positives) / neurons[test_match_to_neurons[ground_truth_unit]]['spike_indices'].size)\n",
    "print(\"True positives are\", 100 * true_positives / test_data.actual_IDs[ground_truth_unit].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CCG between the sorted units and the ground truth units for comparison\n",
    "counts, time_axis = fbp.analyze_spike_timing.zero_symmetric_ccg(neurons[test_match_to_neurons[0]]['spike_indices'], \n",
    "                                                                neurons[test_match_to_neurons[1]]['spike_indices'], 20*40, 40)\n",
    "plt.bar(time_axis, counts, width=1, color=[.5, .5, .5])\n",
    "plt.plot(time_axis, counts, color='k')\n",
    "\n",
    "# CCG for actual data for comparison\n",
    "counts, time_axis = fbp.analyze_spike_timing.zero_symmetric_ccg(test_data.actual_IDs[0], test_data.actual_IDs[1], 20*40, 40)\n",
    "plt.plot(time_axis, counts, color='r')\n",
    "\n",
    "plt.axvline(0, color=[.75, .75, .75])\n",
    "plt.axvline(10, color=[.75, .75, .75])\n",
    "plt.axvline(-10, color=[.75, .75, .75])\n",
    "plt.axvline(5, color=[.75, .75, .75])\n",
    "plt.axvline(-5, color=[.75, .75, .75])\n",
    "# plt.ylim(0, 400)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
